name: Twitter Data Scraper

on:
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Batch size (random N users from database)'
        required: false
        default: '20'
      frequency_group:
        description: 'User frequency group to scrape'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - high     # é«˜é¢‘ç”¨æˆ· (æ¯2å°æ—¶)
          - medium   # ä¸­é¢‘ç”¨æˆ· (æ¯4å°æ—¶)
          - low      # ä½é¢‘ç”¨æˆ· (æ¯6å°æ—¶)

  # è‡ªåŠ¨å®šæ—¶ä»»åŠ¡ï¼ˆåŒ—äº¬æ—¶é—´ 8-24ç‚¹ï¼‰
  schedule:
    # é«˜é¢‘ç”¨æˆ·ï¼šæ¯2å°æ—¶ (åŒ—äº¬æ—¶é—´ 8, 10, 12, 14, 16, 18, 20, 22ç‚¹)
    - cron: '0 0,2,4,6,8,10,12,14 * * *'
    # ä¸­é¢‘ç”¨æˆ·ï¼šæ¯4å°æ—¶ (åŒ—äº¬æ—¶é—´ 8, 12, 16, 20ç‚¹)
    - cron: '30 0,4,8,12 * * *'
    # ä½é¢‘ç”¨æˆ·ï¼šæ¯6å°æ—¶ (åŒ—äº¬æ—¶é—´ 8, 14, 20ç‚¹)
    - cron: '45 0,6,12 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      HEADLESS: true
      WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      TWITTER_COOKIES_JSON: ${{ secrets.TWITTER_COOKIES_JSON }}
      EXT_TWEET_PATH: ./TwExport/2.6.0_0
      EXT_FOLLOWER_PATH: ./Twitter Export Follower/3.8.0_0

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run scraper
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          SCHEDULE_CRON: ${{ github.event.schedule }}
          INPUT_FREQ: ${{ github.event.inputs.frequency_group || 'all' }}
          INPUT_BATCH: ${{ github.event.inputs.batch_size || '' }}
        run: |
          # å®šæ—¶ä»»åŠ¡æ ¹æ®è§¦å‘çš„ cron è¡¨è¾¾å¼ç¡®å®šé¢‘ç‡ç»„ï¼ˆé¿å…æ‰§è¡Œå»¶è¿Ÿå¯¼è‡´çš„æ—¶é—´æ¼‚ç§»ï¼‰
          if [ "$EVENT_NAME" = "schedule" ]; then
            # ä» cron è¡¨è¾¾å¼ä¸­æå–åˆ†é’Ÿæ•°ï¼ˆæ ¼å¼: "M H * * *"ï¼‰
            CRON_MINUTE=$(echo "$SCHEDULE_CRON" | awk '{print $1}')
            case $CRON_MINUTE in
              0)  FREQ="high";   BATCH_SIZE=15;;  # é«˜é¢‘ç”¨æˆ·ï¼šé‡‡é›†é¢‘ç¹ï¼Œæ¯æ¬¡å°‘é‡
              30) FREQ="medium"; BATCH_SIZE=25;;  # ä¸­é¢‘ç”¨æˆ·ï¼šé€‚ä¸­
              45) FREQ="low";    BATCH_SIZE=30;;  # ä½é¢‘ç”¨æˆ·ï¼šé‡‡é›†å°‘ï¼Œæ¯æ¬¡å¤šé‡
              *)  FREQ="all";    BATCH_SIZE=20;;
            esac
            echo "ğŸ“… è§¦å‘çš„ cron: $SCHEDULE_CRON (åˆ†é’Ÿ=$CRON_MINUTE)"
          else
            FREQ="$INPUT_FREQ"
            BATCH_SIZE="${INPUT_BATCH:-20}"  # æ‰‹åŠ¨è§¦å‘ä½¿ç”¨è¾“å…¥å€¼æˆ–é»˜è®¤20
          fi
          echo "ğŸš€ é¢‘ç‡ç»„: $FREQ, æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
          npm run batch -- --batch-size=$BATCH_SIZE --frequency=$FREQ

      - name: Notify on failure
        if: failure() && env.WEBHOOK_URL != ''
        run: |
          curl -X POST ${{ env.WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d "{\"text\":\"âŒ Twitter scraper failed! Run #${{ github.run_number }}\"}" || true
